{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/multi-agent-parameter-evasion-simulation-lab?scriptVersionId=296384381\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# DaScient Multi-Agent Parameter Lab (Kaggle Handbook)\n## Transformer Decoding Benchmarks on a Pursuit–Evasion Simulation\n\n**Version:** 1.0  \n**Purpose:** Educational benchmarking of transformer model tunable parameters (temperature, top_p, max_tokens, etc.)  \n**Domains:** Multi-agent kinematics, structured generation, eval harness design, reproducible experiments\n\n### What you will learn\n- How decoding parameters change model behavior and reliability\n- How to evaluate LLM outputs with objective checks (JSON validity, constraints, determinism)\n- How to connect LLM-generated policies to an abstract simulation\n- How to build a mini leaderboard suitable for Kaggle\n\n### Safety note\nThis notebook implements an **abstract pursuit–evasion sandbox** (no weapons, no targeting, no combat systems).","metadata":{}},{"cell_type":"code","source":"import os, re, json, math, time, random\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport plotly.graph_objects as go","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:00:39.633446Z","iopub.execute_input":"2026-02-07T13:00:39.63447Z","iopub.status.idle":"2026-02-07T13:00:41.414388Z","shell.execute_reply.started":"2026-02-07T13:00:39.634437Z","shell.execute_reply":"2026-02-07T13:00:41.413535Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"\n\nCell 3 (Markdown) | Reproducibility\n\n## Reproducibility\nWe fix seeds for the simulator and (when possible) generation.\nNote: some hosted APIs are nondeterministic even at temperature 0.","metadata":{}},{"cell_type":"code","source":"SEED = 1337\nrandom.seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:00:42.239643Z","iopub.execute_input":"2026-02-07T13:00:42.240178Z","iopub.status.idle":"2026-02-07T13:00:42.244622Z","shell.execute_reply.started":"2026-02-07T13:00:42.240147Z","shell.execute_reply":"2026-02-07T13:00:42.243845Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"\nCell 5 (Markdown) | Simulator definition (abstract pursuit–evasion)\n\n## Abstract Pursuit–Evasion Simulator\nWe simulate agents moving in 2D with bounded acceleration, drag, and a simple capture rule.\n\n- Evaders try to maximize distance from pursuers\n- Pursuers try to minimize distance to the nearest evader\n- LLMs generate policy parameters in a structured JSON format","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass SimConfig:\n    dt: float = 0.1\n    steps: int = 600\n    world_size: float = 200.0\n    drag: float = 0.02\n    max_speed: float = 25.0\n    max_accel: float = 18.0\n    capture_radius: float = 3.0\n\n@dataclass\nclass TeamPolicy:\n    # Interpretable knobs the LLM can set\n    cohesion: float\n    separation: float\n    alignment: float\n    goal_seek: float\n    jitter: float\n    max_speed_scale: float\n\ndef _clip_norm(v: np.ndarray, max_norm: float) -> np.ndarray:\n    n = np.linalg.norm(v) + 1e-12\n    if n > max_norm:\n        return v * (max_norm / n)\n    return v\n\ndef _wrap(pos: np.ndarray, world_size: float) -> np.ndarray:\n    # torus world\n    return (pos + world_size) % (2 * world_size) - world_size\n\ndef initialize_state(n_pursuers=3, n_evaders=6, cfg: SimConfig = SimConfig()):\n    purs_pos = np.random.uniform(-cfg.world_size, cfg.world_size, size=(n_pursuers, 2))\n    evad_pos = np.random.uniform(-cfg.world_size, cfg.world_size, size=(n_evaders, 2))\n    purs_vel = np.random.uniform(-1, 1, size=(n_pursuers, 2))\n    evad_vel = np.random.uniform(-1, 1, size=(n_evaders, 2))\n    return purs_pos, purs_vel, evad_pos, evad_vel\n\ndef nearest_dist(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n    # returns min dist from each row in a to any row in b\n    d = np.sqrt(((a[:, None, :] - b[None, :, :]) ** 2).sum(axis=2))\n    return d.min(axis=1)\n\ndef boids_force(pos: np.ndarray, vel: np.ndarray, cfg: SimConfig, pol: TeamPolicy) -> np.ndarray:\n    # Cohesion, separation, alignment computed within team\n    n = pos.shape[0]\n    if n <= 1:\n        return np.zeros_like(pos)\n\n    center = pos.mean(axis=0, keepdims=True)\n    cohesion_vec = (center - pos)\n\n    sep = np.zeros_like(pos)\n    for i in range(n):\n        diff = pos[i] - pos\n        dist = np.linalg.norm(diff, axis=1) + 1e-12\n        mask = (dist < 12.0) & (dist > 0)\n        if mask.any():\n            sep[i] = (diff[mask] / (dist[mask][:, None] ** 2)).sum(axis=0)\n\n    align = (vel.mean(axis=0, keepdims=True) - vel)\n\n    jitter = np.random.uniform(-1, 1, size=pos.shape)\n\n    force = (\n        pol.cohesion * cohesion_vec\n        + pol.separation * sep\n        + pol.alignment * align\n        + pol.jitter * jitter\n    )\n    return force\n\ndef simulate_episode(\n    cfg: SimConfig,\n    purs_pol: TeamPolicy,\n    evad_pol: TeamPolicy,\n    n_pursuers=3,\n    n_evaders=6,\n) -> Dict[str, Any]:\n    purs_pos, purs_vel, evad_pos, evad_vel = initialize_state(n_pursuers, n_evaders, cfg)\n\n    traj = {\n        \"purs_pos\": [],\n        \"evad_pos\": [],\n        \"min_dist\": [],\n        \"captured\": []\n    }\n\n    captured = np.zeros(n_evaders, dtype=bool)\n\n    for t in range(cfg.steps):\n        # pursuers chase nearest evader\n        active_e = evad_pos[~captured]\n        if active_e.shape[0] == 0:\n            break\n\n        # boids-like internal forces\n        purs_force = boids_force(purs_pos, purs_vel, cfg, purs_pol)\n        evad_force = boids_force(evad_pos, evad_vel, cfg, evad_pol)\n\n        # goal forces\n        # pursuers: toward nearest active evader\n        dmat = np.sqrt(((purs_pos[:, None, :] - active_e[None, :, :]) ** 2).sum(axis=2))\n        nn = dmat.argmin(axis=1)\n        target = active_e[nn]\n        purs_goal = (target - purs_pos)\n\n        # evaders: away from nearest pursuer\n        dmat2 = np.sqrt(((evad_pos[:, None, :] - purs_pos[None, :, :]) ** 2).sum(axis=2))\n        nn2 = dmat2.argmin(axis=1)\n        away = (evad_pos - purs_pos[nn2])\n\n        purs_acc = purs_force + purs_pol.goal_seek * purs_goal\n        evad_acc = evad_force + evad_pol.goal_seek * away\n\n        # accel limits\n        purs_acc = np.array([_clip_norm(a, cfg.max_accel) for a in purs_acc])\n        evad_acc = np.array([_clip_norm(a, cfg.max_accel) for a in evad_acc])\n\n        # integrate + drag\n        purs_vel = purs_vel * (1 - cfg.drag) + purs_acc * cfg.dt\n        evad_vel = evad_vel * (1 - cfg.drag) + evad_acc * cfg.dt\n\n        purs_vel = np.array([_clip_norm(v, cfg.max_speed * purs_pol.max_speed_scale) for v in purs_vel])\n        evad_vel = np.array([_clip_norm(v, cfg.max_speed * evad_pol.max_speed_scale) for v in evad_vel])\n\n        purs_pos = _wrap(purs_pos + purs_vel * cfg.dt, cfg.world_size)\n        evad_pos = _wrap(evad_pos + evad_vel * cfg.dt, cfg.world_size)\n\n        # capture check\n        dcap = np.sqrt(((evad_pos[None, :, :] - purs_pos[:, None, :]) ** 2).sum(axis=2))\n        newly = (dcap.min(axis=0) < cfg.capture_radius) & (~captured)\n        captured[newly] = True\n\n        traj[\"purs_pos\"].append(purs_pos.copy())\n        traj[\"evad_pos\"].append(evad_pos.copy())\n        traj[\"min_dist\"].append(float(dcap.min()))\n        traj[\"captured\"].append(int(captured.sum()))\n\n        if captured.all():\n            break\n\n    result = {\n        \"steps_run\": len(traj[\"min_dist\"]),\n        \"min_dist_final\": traj[\"min_dist\"][-1] if traj[\"min_dist\"] else None,\n        \"captured_total\": int(captured.sum()),\n        \"capture_rate\": float(captured.mean()),\n        \"trajectory\": traj\n    }\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:00:45.096421Z","iopub.execute_input":"2026-02-07T13:00:45.096814Z","iopub.status.idle":"2026-02-07T13:00:45.120888Z","shell.execute_reply.started":"2026-02-07T13:00:45.096781Z","shell.execute_reply":"2026-02-07T13:00:45.119879Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Policy JSON schema\nModels must output a single JSON object of this form:\n\n```json\n{\n  \"pursuers\": {\"cohesion\": 0.1, \"separation\": 0.8, \"alignment\": 0.2, \"goal_seek\": 1.3, \"jitter\": 0.05, \"max_speed_scale\": 1.1},\n  \"evaders\":  {\"cohesion\": 0.2, \"separation\": 1.2, \"alignment\": 0.3, \"goal_seek\": 1.6, \"jitter\": 0.08, \"max_speed_scale\": 1.2}\n}\n\nAll values must be floats within safe bounds, enforced by validators.","metadata":{}},{"cell_type":"code","source":"BOUNDS = {\n    \"cohesion\": (0.0, 2.0),\n    \"separation\": (0.0, 3.0),\n    \"alignment\": (0.0, 2.0),\n    \"goal_seek\": (0.0, 3.0),\n    \"jitter\": (0.0, 0.5),\n    \"max_speed_scale\": (0.6, 1.6),\n}\n\ndef extract_json(text: str) -> Optional[Dict[str, Any]]:\n    # best-effort JSON extraction\n    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n    if not m:\n        return None\n    try:\n        return json.loads(m.group(0))\n    except Exception:\n        return None\n\ndef validate_policy_obj(obj: Dict[str, Any]) -> Tuple[bool, List[str]]:\n    errs = []\n    for side in [\"pursuers\", \"evaders\"]:\n        if side not in obj or not isinstance(obj[side], dict):\n            errs.append(f\"missing side: {side}\")\n            continue\n        for k, (lo, hi) in BOUNDS.items():\n            if k not in obj[side]:\n                errs.append(f\"{side}.{k} missing\")\n                continue\n            v = obj[side][k]\n            if not isinstance(v, (int, float)):\n                errs.append(f\"{side}.{k} not numeric\")\n                continue\n            if not (lo <= float(v) <= hi):\n                errs.append(f\"{side}.{k} out of bounds [{lo}, {hi}]\")\n    return (len(errs) == 0), errs\n\ndef to_team_policy(d: Dict[str, Any]) -> TeamPolicy:\n    return TeamPolicy(**{k: float(d[k]) for k in BOUNDS.keys()})\n\ndef default_policy() -> Dict[str, Any]:\n    return {\n        \"pursuers\": {\"cohesion\": 0.10, \"separation\": 0.60, \"alignment\": 0.20, \"goal_seek\": 1.30, \"jitter\": 0.05, \"max_speed_scale\": 1.10},\n        \"evaders\":  {\"cohesion\": 0.15, \"separation\": 1.10, \"alignment\": 0.25, \"goal_seek\": 1.60, \"jitter\": 0.08, \"max_speed_scale\": 1.20},\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:01.589636Z","iopub.execute_input":"2026-02-07T13:01:01.589996Z","iopub.status.idle":"2026-02-07T13:01:01.600633Z","shell.execute_reply.started":"2026-02-07T13:01:01.589967Z","shell.execute_reply":"2026-02-07T13:01:01.599697Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Model adapters\nKaggle-friendly default: Hugging Face local model (small).  \nOptional: OpenAI, Gemini, Grok adapters if you enable internet and provide keys via Kaggle Secrets.\n\nTip: On Kaggle, use **Add-ons -> Secrets** and store environment variables like:\n- OPENAI_API_KEY\n- GEMINI_API_KEY\n- XAI_API_KEY","metadata":{}},{"cell_type":"code","source":"# If transformers is not installed in your Kaggle image, uncomment:\n# !pip -q install transformers accelerate\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nHF_MODEL_NAME = \"distilgpt2\"  # small, fast, educational baseline\ntokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(HF_MODEL_NAME)\n\ndef hf_generate(prompt: str, temperature=0.7, top_p=0.9, max_new_tokens=200, seed=SEED) -> str:\n    # best-effort determinism\n    torch_seed_ok = False\n    try:\n        import torch\n        torch.manual_seed(seed)\n        torch_seed_ok = True\n    except Exception:\n        pass\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    out = model.generate(\n        **inputs,\n        do_sample=(temperature > 0),\n        temperature=max(1e-6, float(temperature)),\n        top_p=float(top_p),\n        max_new_tokens=int(max_new_tokens),\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    return tokenizer.decode(out[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:11.518578Z","iopub.execute_input":"2026-02-07T13:01:11.519404Z","iopub.status.idle":"2026-02-07T13:01:48.21827Z","shell.execute_reply.started":"2026-02-07T13:01:11.519367Z","shell.execute_reply":"2026-02-07T13:01:48.217179Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75e4020659b4d8b902c5caf3ab5b49c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2d7a614ed14c8e86146a33fe41f8a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78bb7abadab46a28d4320a6cfc61774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb3fb9b38664a9193ee81ddc25c996c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275936f292b74b529b01bc520a6dc20f"}},"metadata":{}},{"name":"stderr","text":"2026-02-07 13:01:29.373506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770469289.591524      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770469289.657874      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770469290.206624      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770469290.206677      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770469290.206680      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770469290.206682      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f07f0205cc23423eae3f2d281cef5f6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c8a9d1bd414f05bc6e5feb7b5cf72b"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class Provider:\n    def __init__(self, name: str):\n        self.name = name\n\n    def generate(self, prompt: str, **kwargs) -> str:\n        raise NotImplementedError(\"Implement per provider, enable only if you have keys and internet.\")\n\n# Safe placeholders you can fill in for your own experiments.\n# Keep keys in Kaggle Secrets, never hardcode.\n\nclass OpenAIProvider(Provider):\n    def __init__(self, model_name: str):\n        super().__init__(\"openai\")\n        self.model_name = model_name\n\n    def generate(self, prompt: str, temperature=0.7, top_p=0.9, max_tokens=300):\n        # Pseudocode only. Fill with your preferred OpenAI SDK if enabled.\n        raise NotImplementedError\n\nclass GeminiProvider(Provider):\n    def __init__(self, model_name: str):\n        super().__init__(\"gemini\")\n        self.model_name = model_name\n\n    def generate(self, prompt: str, temperature=0.7, top_p=0.9, max_tokens=300):\n        raise NotImplementedError\n\nclass GrokProvider(Provider):\n    def __init__(self, model_name: str):\n        super().__init__(\"grok\")\n        self.model_name = model_name\n\n    def generate(self, prompt: str, temperature=0.7, top_p=0.9, max_tokens=300):\n        raise NotImplementedError","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:48.219816Z","iopub.execute_input":"2026-02-07T13:01:48.221204Z","iopub.status.idle":"2026-02-07T13:01:48.229046Z","shell.execute_reply.started":"2026-02-07T13:01:48.221164Z","shell.execute_reply":"2026-02-07T13:01:48.228078Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Prompt template\nWe constrain the model to output only JSON and we restate bounds.\nThis is where decoding parameters matter a lot.","metadata":{}},{"cell_type":"code","source":"def build_prompt(task_desc: str) -> str:\n    bounds_str = \"\\n\".join([f\"- {k}: [{lo}, {hi}]\" for k, (lo, hi) in BOUNDS.items()])\n    return f\"\"\"\nYou are tuning two teams in an abstract pursuit–evasion simulation.\nReturn ONLY valid JSON, no commentary.\n\nTask:\n{task_desc}\n\nPolicy JSON schema:\n{{\n  \"pursuers\": {{\"cohesion\": ..., \"separation\": ..., \"alignment\": ..., \"goal_seek\": ..., \"jitter\": ..., \"max_speed_scale\": ...}},\n  \"evaders\":  {{\"cohesion\": ..., \"separation\": ..., \"alignment\": ..., \"goal_seek\": ..., \"jitter\": ..., \"max_speed_scale\": ...}}\n}}\n\nBounds:\n{bounds_str}\n\nGoal:\n- pursuers should capture more evaders quickly\n- evaders should survive longer\nBalance both so results are not trivial.\n\nReturn ONLY JSON.\n\"\"\".strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:48.230263Z","iopub.execute_input":"2026-02-07T13:01:48.230786Z","iopub.status.idle":"2026-02-07T13:01:48.249688Z","shell.execute_reply.started":"2026-02-07T13:01:48.230744Z","shell.execute_reply":"2026-02-07T13:01:48.248744Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Parameter sweep\nWe compare settings across:\n- temperature\n- top_p\n- max_new_tokens (or max_tokens)\n- optional: repetition penalty (HF), presence penalty (some APIs)\n\nMetrics:\n- JSON validity rate\n- constraint pass rate\n- simulation score (capture_rate, steps_run, min_dist trend)\n- stability proxy (variance across seeds)\n- runtime per trial","metadata":{}},{"cell_type":"code","source":"def run_trial_hf(task_desc: str, gen_params: Dict[str, Any], sim_cfg: SimConfig, seed: int) -> Dict[str, Any]:\n    prompt = build_prompt(task_desc)\n    t0 = time.time()\n    text = hf_generate(prompt, seed=seed, **gen_params)\n    dt = time.time() - t0\n\n    obj = extract_json(text)\n    if obj is None:\n        obj = default_policy()\n        valid_json = 0\n    else:\n        valid_json = 1\n\n    ok, errs = validate_policy_obj(obj)\n    if not ok:\n        obj = default_policy()\n\n    purs_pol = to_team_policy(obj[\"pursuers\"])\n    evad_pol = to_team_policy(obj[\"evaders\"])\n\n    sim = simulate_episode(sim_cfg, purs_pol, evad_pol)\n    score = (sim[\"capture_rate\"] * 100.0) - (sim[\"steps_run\"] / sim_cfg.steps * 20.0)\n\n    return {\n        \"provider\": \"hf\",\n        \"model\": HF_MODEL_NAME,\n        \"seed\": seed,\n        \"gen_params\": json.dumps(gen_params, sort_keys=True),\n        \"valid_json\": valid_json,\n        \"constraints_ok\": int(ok),\n        \"errors\": \"; \".join(errs)[:200],\n        \"runtime_s\": dt,\n        \"capture_rate\": sim[\"capture_rate\"],\n        \"captured_total\": sim[\"captured_total\"],\n        \"steps_run\": sim[\"steps_run\"],\n        \"min_dist_final\": sim[\"min_dist_final\"],\n        \"score\": score,\n        \"trajectory\": sim[\"trajectory\"],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:56.416206Z","iopub.execute_input":"2026-02-07T13:01:56.416564Z","iopub.status.idle":"2026-02-07T13:01:56.427083Z","shell.execute_reply.started":"2026-02-07T13:01:56.416533Z","shell.execute_reply":"2026-02-07T13:01:56.426016Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"TASK = \"Tune pursuit and evasion behaviors for a mixed group encounter. Avoid extreme jitter. Keep motion stable.\"\n\nsim_cfg = SimConfig()\n\ngrid = [\n    {\"temperature\": 0.0, \"top_p\": 1.0, \"max_new_tokens\": 220},\n    {\"temperature\": 0.2, \"top_p\": 0.95, \"max_new_tokens\": 220},\n    {\"temperature\": 0.6, \"top_p\": 0.90, \"max_new_tokens\": 220},\n    {\"temperature\": 0.9, \"top_p\": 0.92, \"max_new_tokens\": 220},\n]\n\nseeds = [SEED, SEED + 1, SEED + 2]\n\nrows = []\nfor gen_params in grid:\n    for sd in seeds:\n        rows.append(run_trial_hf(TASK, gen_params, sim_cfg, seed=sd))\n\ndf = pd.DataFrame(rows)\n\nleader = (\n    df.groupby([\"provider\", \"model\", \"gen_params\"], as_index=False)\n      .agg(\n          score_mean=(\"score\", \"mean\"),\n          score_std=(\"score\", \"std\"),\n          valid_json_rate=(\"valid_json\", \"mean\"),\n          constraints_rate=(\"constraints_ok\", \"mean\"),\n          runtime_mean=(\"runtime_s\", \"mean\"),\n          capture_rate_mean=(\"capture_rate\", \"mean\"),\n          steps_mean=(\"steps_run\", \"mean\"),\n      )\n      .sort_values([\"score_mean\", \"valid_json_rate\"], ascending=False)\n)\n\nleader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T13:01:58.112733Z","iopub.execute_input":"2026-02-07T13:01:58.113104Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"fig = px.scatter(\n    leader,\n    x=\"valid_json_rate\",\n    y=\"score_mean\",\n    error_y=\"score_std\",\n    hover_data=[\"gen_params\", \"capture_rate_mean\", \"steps_mean\", \"runtime_mean\"],\n    title=\"Decoding reliability vs simulation score\"\n)\nfig.show()\n\nfig2 = px.bar(\n    leader.sort_values(\"runtime_mean\"),\n    x=\"gen_params\",\n    y=\"runtime_mean\",\n    title=\"Generation runtime by decoding settings\"\n)\nfig2.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cell 18 (Markdown) | Interactive trajectory viewer (Kaggle-safe)\n\n## Interactive trajectory viewer\nPick one run and visualize pursuer and evader positions over time.\nThis is Plotly-based and works well on Kaggle.","metadata":{}},{"cell_type":"code","source":"def animate_run(row_idx: int):\n    traj = df.loc[row_idx, \"trajectory\"]\n    purs = np.array(traj[\"purs_pos\"])  # [T, P, 2]\n    evad = np.array(traj[\"evad_pos\"])  # [T, E, 2]\n    T = purs.shape[0]\n\n    frames = []\n    for t in range(T):\n        frames.append(go.Frame(\n            data=[\n                go.Scatter(x=purs[t,:,0], y=purs[t,:,1], mode=\"markers\", name=\"pursuers\"),\n                go.Scatter(x=evad[t,:,0], y=evad[t,:,1], mode=\"markers\", name=\"evaders\"),\n            ],\n            name=str(t)\n        ))\n\n    fig = go.Figure(\n        data=[\n            go.Scatter(x=purs[0,:,0], y=purs[0,:,1], mode=\"markers\", name=\"pursuers\"),\n            go.Scatter(x=evad[0,:,0], y=evad[0,:,1], mode=\"markers\", name=\"evaders\"),\n        ],\n        frames=frames\n    )\n\n    fig.update_layout(\n        title=f\"Run {row_idx} | captured_total={df.loc[row_idx,'captured_total']} | gen_params={df.loc[row_idx,'gen_params']}\",\n        xaxis=dict(range=[-sim_cfg.world_size, sim_cfg.world_size]),\n        yaxis=dict(range=[-sim_cfg.world_size, sim_cfg.world_size]),\n        updatemenus=[{\n            \"type\": \"buttons\",\n            \"buttons\": [\n                {\"label\": \"Play\", \"method\": \"animate\", \"args\": [None, {\"frame\": {\"duration\": 50, \"redraw\": True}, \"fromcurrent\": True}]},\n                {\"label\": \"Pause\", \"method\": \"animate\", \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]},\n            ],\n        }]\n    )\n    fig.show()\n\n# Example: animate the best row by score\nbest_row = df[\"score\"].idxmax()\nanimate_run(best_row)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exercises\n1) Add a new metric: \"trajectory smoothness\" using acceleration variance.  \n2) Make the prompt stricter: require 3 decimals, forbid extra keys, and compare validity rates.  \n3) Swap HF model to a small instruction-tuned model and measure improvement.  \n4) Add an \"analysis summary\" task: ask the model to explain why a policy worked, then score factuality against telemetry.\n\n## Extensions\n- Implement a cost model: tokens * price for API models (user-supplied pricing)\n- Add repeated trials and compute confidence intervals\n- Export a Kaggle dataset: leaderboard.csv + example trajectories","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2026-02-07T13:00:24.47879Z","iopub.status.idle":"2026-02-07T13:00:24.479148Z","shell.execute_reply.started":"2026-02-07T13:00:24.47899Z","shell.execute_reply":"2026-02-07T13:00:24.479014Z"}}},{"cell_type":"code","source":"# en fin","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}